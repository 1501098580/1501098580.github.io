<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/post/16107.html</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>test</title>
    <url>/post/d87f7e0c.html</url>
    <content><![CDATA[<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">test文件</span><br><span class="line">撒很难过船</span><br><span class="line"></span><br><span class="line">大萨达</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/23/eKFWfmxuVjSndR6.jpg"></p>
]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>人脸识别一</title>
    <url>/post/937cd58.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>注意力机制</title>
    <url>/post/141d1667.html</url>
    <content><![CDATA[<h1 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">注意力机制的核心在于通过计算一个注意力map，来强调最相关的特征，并避免不相关特征的干扰。</span><br><span class="line">获取注意力map的方法可分为两类：无参数、有参数，如图6所示，主要的区别在于注意图中的重要性权重是否可学习：</span><br><span class="line">注意力机制为深度网络提供了突出给定图像中最重要区域的能力</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1D 通道注意力(任务)</span><br><span class="line">2D 空间注意力</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">对于1D数据来说，在注意力方面，SE仅关注了通道注意力，没考虑空间方面的注意力。</span><br></pre></td></tr></table></figure>

<h3 id="Encoder-Decoder"><a href="#Encoder-Decoder" class="headerlink" title="Encoder-Decoder"></a>Encoder-Decoder</h3><h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h3>]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>深度学习</tag>
        <tag>注意力机制</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习之生成网络cyclegan</title>
    <url>/post/8b28088e.html</url>
    <content><![CDATA[<h1 id="Cyclegan"><a href="#Cyclegan" class="headerlink" title="Cyclegan"></a>Cyclegan</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">贡献：</span><br><span class="line">	提出了循环一致性损失</span><br><span class="line">	使用非对称的数据就可以进行风格转换</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">总共使用了两队生成器和判别器。</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/24/Bdo5CKXvTqup4jJ.png"></p>
<p><img src="https://i.loli.net/2021/10/24/XCteayNqGjv46ZW.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">循环一致性损失：相当于一张图片风格为A，通过G_AB 生成风格为B的假图 -&gt; fake_B,</span><br><span class="line">然后通过 G_BA 生成风格为A假图 fake_A,最终得到的fake_A能够骗过D_A，反之亦然。</span><br><span class="line">A -G_AB&gt; fake_B -G_BA&gt; fake_A</span><br><span class="line">为什么循环一致性损失能够保证在非对称的数据下，图像的内容信息不会改变？</span><br><span class="line"></span><br><span class="line">简单来说：判别器是判断图像风格的，如果没有循环一致性损失时，从源域（风格A）到目标域（风格B）中任意一个或许是最简单的方法，</span><br><span class="line">但是当加入了循环一致性损失后，从源域到目标域的变化中，最简单的方法是只变化风格，而不变化内容，从而约束了生成器的生成。</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>生成网络</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>深度学习</tag>
        <tag>生成网络</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习之生成网络gan</title>
    <url>/post/f5c1817e.html</url>
    <content><![CDATA[<h1 id="Gan"><a href="#Gan" class="headerlink" title="Gan"></a>Gan</h1><h1 id="Gan的改进"><a href="#Gan的改进" class="headerlink" title="Gan的改进"></a>Gan的改进</h1>]]></content>
      <categories>
        <category>生成网络</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>深度学习</tag>
        <tag>生成网络</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习基础一</title>
    <url>/post/9f799b3c.html</url>
    <content><![CDATA[<h1 id="卷积-cnn"><a href="#卷积-cnn" class="headerlink" title="卷积(cnn)"></a>卷积(cnn)</h1><p><img src="https://i.loli.net/2021/10/24/YqCZOxnU51ELi8Q.png"></p>
<p><img src="https://i.loli.net/2021/10/24/7n9Si4u1d6l3oIN.gif"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">卷积核：简单来说就可以看做一个特征提取器。</span><br><span class="line"></span><br><span class="line">步长stride：每次卷积核在特征图上滑动的步长，默认只滑动一个像素。</span><br><span class="line">			当滑动的步长越大，输出的特征图(feature map)就越小，相当于下面说的，池化操作。</span><br><span class="line">			</span><br><span class="line">padding操作：填充，对于图像边缘的像素来说，只进行了一次卷积操作，而内部的卷积则进行了至少两次卷积操作，</span><br><span class="line">	作用有两个：</span><br><span class="line">		1、通过填充后，可以使得卷积后的feature map 和原来的feature map一样的大小,</span><br><span class="line">			可以用来控制卷积层输出的特征图的大小。</span><br><span class="line">		2、通过对边缘向外填充像素点，来使得边缘像素点，也来充分提取特征。</span><br><span class="line"></span><br><span class="line">感受野：由于卷积操作后，假如是3*3的卷积核，对应于原来的feature map，3*3区域大小的像素</span><br><span class="line">	就变为了一个像素区域，因此输出的feature map就相当于原来的3*3的大小，随着卷积层的</span><br><span class="line">	加深，感受野也会越来越大。</span><br></pre></td></tr></table></figure>

<p>当只有一个卷积核时学习到的特征有限，因此需要多个卷积核：</p>
<p><img src="https://i.loli.net/2021/10/24/upofgIP5DrBdbXe.png"></p>
<p><img src="https://i.loli.net/2021/10/24/in7tUKYS4jWOywx.png" alt="0005"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">一组多个卷积核就能学到多个特征。</span><br><span class="line">对于k个卷积核中的一个卷积核，每张特征图上对应一个卷积核，</span><br><span class="line">在卷积的时候，每张特征图上卷积核不是同一个卷积核，</span><br><span class="line">也就是说对于3通道来说，卷积核就变为了3D，也就是3个卷积核。</span><br><span class="line">卷积完后，然后相加，就变为了一个feature map</span><br><span class="line">对于k个卷积核，最终会得到k个feature map。</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/24/qO12soTD6GRlpc3.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">通过上面的例子再说一下：</span><br><span class="line">1、上面图上有两个卷积核，都是3*3的，每个卷积核上的值叫做权重  Bias b是偏置，可以不用管</span><br><span class="line">2、3*3的卷积核，因为上一层feature map是3个，也就是通道数是3，卷积核就会变为3*3*3</span><br><span class="line">3、且每个卷积核不是同一个卷积核，然后每个卷积核和对应的卷积层进行卷积，得到的值，</span><br><span class="line">然后相加，最终变为一个值，图中就是5.</span><br></pre></td></tr></table></figure>



<h3 id="1、输入层"><a href="#1、输入层" class="headerlink" title="1、输入层"></a>1、输入层</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">一般是一张图像 H*W*C</span><br><span class="line">H：图像高 W ：图像宽 c：图像通道数，刚开始图像通道数为3，RGB</span><br></pre></td></tr></table></figure>

<h3 id="2、卷积层"><a href="#2、卷积层" class="headerlink" title="2、卷积层"></a>2、卷积层</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">就是我们刚才说的卷积操作。</span><br><span class="line"></span><br><span class="line">有一点需要注意，每层的卷积核是权重共享的。</span><br><span class="line"></span><br><span class="line">为什么要多层卷积？？？？</span><br><span class="line">卷积一直在做的一件事就是对特征提取。</span><br><span class="line">多层卷积相当于做了多次特征提取，随着网络的加深提取到的特征越来越特殊，</span><br><span class="line">越来越能代表这种物体的特征。</span><br></pre></td></tr></table></figure>



<h3 id="3、池化层"><a href="#3、池化层" class="headerlink" title="3、池化层"></a>3、池化层</h3><p><img src="https://i.loli.net/2021/10/24/uGerRDV4a5oOZv2.png" alt="0006"></p>
<p><img src="https://i.loli.net/2021/10/24/SJ1AoQqvflEc7eZ.png" alt="0007"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">特征选择作用：采样层实际上就是一个特征选择的过程，挑选出对我们最有用的信息，去除多余的，冗余的信息</span><br><span class="line">1、最大池化</span><br><span class="line">和卷积核大小类似，加入说我们选2*2的大小，进行池化</span><br><span class="line">最大池化就是说从这2*2 ，也就是4个点中，选择最大的那个，其他舍弃</span><br><span class="line">池化可以一定程度提高空间不变性，比如旋转后，和旋转前，池化是一样的，但是局部有限区域内。</span><br><span class="line"></span><br><span class="line">2、平均池化</span><br><span class="line">就是把四个数加起来除4，当做特征值</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">可以看到，池化说到底还是一个特征选择，信息过滤的过程，我们会损失了一部分信息，来减小参数，计算量</span><br><span class="line">但是现在有的地方也不用池化层了。</span><br></pre></td></tr></table></figure>



<h3 id="4、激活函数-加入非线性"><a href="#4、激活函数-加入非线性" class="headerlink" title="4、激活函数(加入非线性)"></a>4、激活函数(加入非线性)</h3><p><img src="https://i.loli.net/2021/10/24/hLZuNxep4nrMyzf.png" alt="000"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">对于原有的卷积层，只能处理线性问题，对于非线性分类问题解决不了。</span><br><span class="line">那么无论神经网络的层数有多少还是在解决线性函数问题，因为两个线性函数的组合还是线性的。</span><br><span class="line"></span><br><span class="line">因此需要引入非线性函数。</span><br><span class="line">sigmoid函数：</span><br><span class="line">	在反向传播时，容易出现梯度消失</span><br><span class="line">	计算量大</span><br><span class="line">tanh函数：</span><br><span class="line">	在反向传播时，容易出现梯度消失</span><br><span class="line">	计算量大</span><br><span class="line">Relu函数：</span><br><span class="line">	优点：避免梯度消失的问题，通过使得部分神经元为0，抑制作用，避免过拟合问题</span><br><span class="line">	缺点：当值为负数的时候，就会变为0，神经元完全不起作用。</span><br><span class="line">	</span><br><span class="line">注：现在一般都会使用Relu函数和其改进版本，如ELU、PRelu等，从某种程度上避免了使部分神经元死掉的问题。</span><br></pre></td></tr></table></figure>



<h3 id="5、标准化层"><a href="#5、标准化层" class="headerlink" title="5、标准化层"></a>5、标准化层</h3><p><img src="https://i.loli.net/2021/10/24/uBCUmf89LDoShkN.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">什么是标准化？？？</span><br><span class="line">数据的标准化是指将数据按照比例缩放,使之落入一个特定的区间.</span><br><span class="line"></span><br><span class="line">为什么要做标准化？？？</span><br><span class="line">1. 加快网络的训练和收敛的速度</span><br><span class="line">将数据分布在均值为零，方差为1状态下，使得梯度稳定，容易收敛。</span><br><span class="line"></span><br><span class="line">2. 控制梯度爆炸和防止梯度消失</span><br><span class="line">控制数据集中分布在0值附近，有两个好处，</span><br><span class="line">例如sigmoid函数：</span><br><span class="line">1、在经过sigmoid函数将值约束到0附近，梯度不会消失。</span><br><span class="line">因此通常会加在全连接和激励函数之间。</span><br><span class="line">2、如果不使用标准化可能初始loss过大，梯度反向传播就会积累，前面几层会变得非常大，产生梯度爆炸的问题。</span><br><span class="line">而使用标准化后权值就不会很大了。</span><br><span class="line"></span><br><span class="line">3. 防止过拟合</span><br><span class="line">标准化层在使用过程中，通常会以考虑整个batch的数据进行标准化，</span><br><span class="line">考虑整体比只考虑单个肯定能够一定程度上解决过拟合问题</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="6、全连接层"><a href="#6、全连接层" class="headerlink" title="6、全连接层"></a>6、全连接层</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">为什么需要全连接层？</span><br><span class="line">卷积层我们会发现，有一个天生致命的缺点，那就是没有全局，</span><br><span class="line">因此我们需要一个来把握全局的，那就是全连接层。</span><br><span class="line">相当于把前面，每个学习到的特征进行一个汇总操作，使得我们能够把握到整体。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">全连接层如果加深层数，增加神经元输量，网络能力会得到提升，但是也有可能出现过拟合问题。</span><br></pre></td></tr></table></figure>



<h3 id="7、输出层"><a href="#7、输出层" class="headerlink" title="7、输出层"></a>7、输出层</h3><p><img src="https://i.loli.net/2021/10/25/hDmXqrZFkHx2lBe.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">对于分类任务来说：</span><br><span class="line">FC+Softmax+Cross-entropy loss</span><br><span class="line">1、当输入为X, 预测类别为j 的概率为P</span><br><span class="line">2、所有预测类别概率和为1</span><br></pre></td></tr></table></figure>





<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">一句话说就是：卷积层负责提取特征，池化负责特征选择，激活函数增加非线性能力，标准化层用来约束数据分布，全连接层负责分类</span><br></pre></td></tr></table></figure>



<h1 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h1><h3 id="分类损失"><a href="#分类损失" class="headerlink" title="分类损失"></a>分类损失</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、交叉熵损失CE</span><br><span class="line">用于度量两个函数的分布.</span><br><span class="line"></span><br><span class="line">信息熵:去掉冗余信息后的平均信息量。衡量不确定性，不确定性大，信息熵就越大。</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">相对熵(KL散度): 下图</span><br><span class="line">	KL散度用于估计两个分布的相似性</span><br><span class="line">	其中l(p,p)是分布p的熵，而l(p,q)就是p和q的交叉熵。</span><br><span class="line">	假如p是一个已知的分布，则熵是一个常数。</span><br><span class="line">	此时KL与l(p,q)也就是交叉熵只有一个常数的差异，两者是等价的。</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/24/ae6Rd5IFBGs7Myw.jpg"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">交叉熵CE:</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/24/kSmxX8PlvJoji9E.jpg"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">由于交叉熵正负样本平衡，对于正负样本不平衡网络就不能很好的学习</span><br><span class="line">2、平衡交叉熵损失（正负样本不平衡问题）</span><br><span class="line">3、专注难样本 Focal loss（难易样本）</span><br></pre></td></tr></table></figure>



<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">在工程上，经常和softmax loss一起使用：</span><br></pre></td></tr></table></figure>

<p>$$<br>softmax<br>$$</p>
<p><img src="https://i.loli.net/2021/10/25/ZVeDqaf5v4EnKm9.png" alt="image-20211025004211016"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">假如</span><br><span class="line"></span><br><span class="line">输出为 [0.3 0.3 0.4] 目标是 [0 0 1]</span><br><span class="line">则：</span><br><span class="line">	交叉熵为：- (ln(0.3) * 0 + ln(0.3) * 0 + ln(0.4) * 1 ) = - ln4</span><br></pre></td></tr></table></figure>



<h3 id="对于softmax的改进："><a href="#对于softmax的改进：" class="headerlink" title="对于softmax的改进："></a>对于softmax的改进：</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、Large-Margin Softmax Loss L-Softmax loss</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/25/KIV7MAyW6j8sdSB.png" alt="image-20211025005021695"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">这张图显示的是不同softmax loss和L-Softmax loss学习到的特征分布。</span><br><span class="line">第一列就是softmax，第2列是L-Softmax </span><br><span class="line">loss在参数m取不同值时的分布。通过可视化特征可知学习到的类间的特征是比较明显的，但是类内比较散。</span><br><span class="line"></span><br><span class="line">也就是说使得不同类别之间的夹角增大，同时同类分布也更为紧凑。</span><br></pre></td></tr></table></figure>



<p><img src="https://i.loli.net/2021/10/25/aIugtWSJpTvlKxC.png" alt="image-20211025011546484"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">因为最后是全连接层的输出：</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/25/aWOm7K2qAoDjd3S.png" alt="image-20211025011903423"></p>
<p><img src="https://i.loli.net/2021/10/25/5dRUQVgxm8vTjnA.png" alt="image-20211025011941901"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">因为cos在[0,π]上是减函数，</span><br><span class="line">	当f1 &gt; f2 时，也就是说θ1&lt;θ2,样本将被分类为类别1,</span><br><span class="line">	当f1 &lt; f2 时，也就是说θ1&gt;θ2,样本将被分类为类别2,</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/25/uBvEb68Dyoh5TZn.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">L-Softmax损失函数中对角度施加了更为强烈的约束,m&gt;=1</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/25/59VNlbKSinOh3zr.png" alt="image-20211025012636114"></p>
<p><img src="https://i.loli.net/2021/10/25/3L9CA2Qxe4GdlJM.png" alt="image-20211025012807781"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2、Angular Softmax Loss A-Softmax</span><br><span class="line">Angular Softmax Loss(简称A-Softmax loss)与L-Softmax思想类似，主要区别是进一步加入了一个权重约束。</span><br><span class="line">使得||w|| = 1，就变成了</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/25/3GcBTQE9bgL4sVW.png" alt="image-20211025005437525"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">使得类别的判断将只依赖于样本与类别权重的夹角。</span><br></pre></td></tr></table></figure>



<h3 id="回归损失"><a href="#回归损失" class="headerlink" title="回归损失"></a>回归损失</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、L1损失</span><br><span class="line">Mean absolute loss(MAE)也被称为L1 Loss，是以绝对误差作为距离</span><br><span class="line">由于L1 loss具有稀疏性，为了惩罚较大的值，因此常常将其作为正则项添加到其他loss中作为约束。</span><br><span class="line">L1 loss的最大问题是梯度在零点不平滑，导致会跳过极小值。</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/24/53QFT6aUDu4GqrX.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2、L2损失</span><br><span class="line">Mean Squared Loss/ Quadratic Loss(MSE loss)也被称为L2 loss，或欧氏距离，它以误差的平方和作为距离：</span><br><span class="line">L2 loss也常常作为正则项。当预测值与目标值相差很大时, 梯度容易爆炸，因为梯度里包含了x−t。</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/24/oFuUOi58LA6ItaT.png"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">3、L1 loss与L2 loss的改进</span><br><span class="line"></span><br><span class="line">原始的L1 loss和L2 loss都有缺陷，比如L1 loss的最大问题是梯度不平滑，而L2 loss的最大问题是容易梯度爆炸，所以研究者们对其提出了很多的改进。</span><br><span class="line"></span><br><span class="line">在faster rcnn框架中，使用了smooth L1 loss来综合L1与L2 loss的优点。</span><br><span class="line"></span><br><span class="line">在x比较小时，上式等价于L2 loss，保持平滑。在x比较大时，上式等价于L1 loss，可以限制数值的大小。</span><br></pre></td></tr></table></figure>

<p><img src="https://i.loli.net/2021/10/24/NiLIMr5eu2FDfk8.jpg"></p>
<p><img src="https://i.loli.net/2021/10/24/cumGWvkODPKZeqr.png" alt="image-20211024235947407"></p>
<hr>
]]></content>
      <categories>
        <category>深度学习基础</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>目标检测一</title>
    <url>/post/f9b95e7d.html</url>
    <content><![CDATA[<h3 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h3><h3 id="YOLO的改进"><a href="#YOLO的改进" class="headerlink" title="YOLO的改进"></a>YOLO的改进</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、去掉FPN</span><br><span class="line">yolo-f</span><br><span class="line"></span><br><span class="line">2、anchor Free</span><br><span class="line">yolo-x</span><br><span class="line">将每个位置预测个数从3减少到1，并直接预测四个值（即：到网格的左上角的偏移量和box的高宽）；同时，将中心点设为正样本，并预设了一个尺度范围为每个对象指定FPN级别。</span><br><span class="line"></span><br><span class="line">3、NMS-Free</span><br><span class="line">OneNet</span><br><span class="line">4、</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>英语单词一</title>
    <url>/post/afe428e5.html</url>
    <content><![CDATA[<h1 id="A"><a href="#A" class="headerlink" title="A"></a>A</h1>]]></content>
      <categories>
        <category>英语</category>
      </categories>
      <tags>
        <tag>英语</tag>
      </tags>
  </entry>
</search>
